# Splunk 
- Prerequsites for Splunk is a basic understanding of Linux command line
- Splunk Enterprise is a software platform that aggregates and allows search, analysis, and visualization of your infrastructure and host network. 
- Splunk provides real-time visibility to automate the collection, indexing, and alerting of machine data. It also provides machine learning capabilities with artificial intelligence for predictive reporting.

#### Installing Splunk
﻿A new Splunk installation requires configuration to set up the application, as well as tune it to the environment.
﻿
#### Logging in to Splunk
﻿This section covers how to access a fresh Splunk installation and enable secure access by enabling Secure Sockets Layer (SSL) encryption via either the command line or the web application interface.
﻿
#### Splunk Data Ingest
﻿After Splunk is installed and configured, data can be imported for parsing. Once data is loaded, it can be queried and additional search fields can be configured. Adding additional fields to manipulate data can provide context to statistical analysis, and enable quicker searches.
﻿
![c60ebf2b-cc62-42cc-b0e7-20933020f906](https://github.com/paulinoprojects/Splunk/assets/111991325/d4cc76a9-218a-470b-bb69-c61e1f42007b)
- In Splunk environments, data forwarders are used to send data from host endpoints and infrastructure to the Splunk Enterprise indexer. Leveraging data forwarders to send data to an indexer allows for data aggregation at the indexer and for a centrally controlled repository of data for querying and analysis. 

- Data that is ingested into Splunk by manually-entered upload commands may work well in limited data sets but is not efficient when it comes to dynamic enterprise environments. In such environments, Splunk Technology Add-Ons (TAs) are crucial for keeping data sources consistent and reliable.
﻿
#### Getting Data In
- Splunk leverages Forwarders and Technology Add-Ons (TAs) to get data to an index. This section covers how to create and configure an index to receive data from a Splunk TA. Additionally, this section will cover how to install a Universal Forwarder on a Windows 10 host in order to receive log data.
﻿
#### Splunk Common Information Model
- Common Information Model (CIM) compliance is a way for various data sources to become normalized for efficient parsing and analysis. This section covers how to CIM map data that is not received from a Splunk TA.

- Splunk uses the Common Information Model (CIM) for data normalization, which defines universal ways to refer to objects. The CIM is a shared semantic model focused on extracting value from data. Each data model in the CIM consists of a set of field names and tags that define the least common denominator of a domain of interest. Normalized data is critical for a functional Splunk deployment.

#### ﻿Technology Add-On ((TA)
- A Splunk Technology Add-on (TA) enhances the functionality of Splunk by normalizing data, which is often vendor-specific, into a CIM-compliant, normalized data stream. Splunk TAs provide search-time knowledge maps to normalize data for use within the Splunk application.
﻿
- TAs are integral to Splunk and are required additions to an enterprise environment that leverages Splunk. Without the use of TAs, data is not parsed and will remain in its organically generated format.

### Getting Data In: Hot and Cold Buckets
- You will create an index using terms you may not have seen before, such as coldPath and colddb. The temperature-based terminology in the index configuration describes the Splunk data lifecycle. Splunk refers to the folders which store indexed data as buckets. 
﻿
- Hot buckets are at the top of the proverbial pile and are designed to be searched the fastest. Splunk transitions data from hot to warm to cold. It also deletes data due to age, frequency of use, or other reasons outlined in Splunk documentation. Buckets are configured for an index such that an administrator can configure cold data to be stored on cheaper, slower storage.
﻿
- The graphic below shows how an event, such as an HTTP access log, is indexed, then bucketed. Hot buckets are red, closest to the index, to signify top priority for rapid searching.
﻿![20a9b05b-06d9-4fb3-b372-ae429c90badc](https://github.com/paulinoprojects/Splunk/assets/111991325/32deccf1-41b0-41c8-8611-82e12e8596ef)

